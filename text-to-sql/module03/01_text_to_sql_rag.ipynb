{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0916a3a-e402-48b7-a775-ce739e4aeaf4",
   "metadata": {},
   "source": [
    "# RAG(검색 증강 생성)를 활용한 지능형 Text-to-SQL 시스템 구축\n",
    "\n",
    "안녕하세요! 이 노트북에서는 RAG(검색 증강 생성) 기술을 활용하여 자연어 질문을 정확한 SQL 쿼리로 변환하는 시스템을 구축해보겠습니다.\n",
    "\n",
    "## 이 노트북을 통해 배울 수 있는 것\n",
    "- RAG 기술을 활용한 Text-to-SQL 시스템의 원리와 구현\n",
    "- 데이터베이스 메타데이터를 벡터 임베딩으로 변환하고 활용하는 방법\n",
    "- FAISS를 이용한 효율적인 벡터 검색 구현\n",
    "- Amazon Bedrock을 활용한 임베딩 및 LLM 연동\n",
    "- 실제 TPC-DS 데이터셋을 대상으로 한 실습\n",
    "\n",
    "## 배경 지식\n",
    "RAG(Retrieval-Augmented Generation)는 기존 지식 베이스에서 관련 정보를 검색하여 AI 모델의 답변 품질을 향상시키는 기술입니다. Text-to-SQL 분야에서 RAG를 활용하면 데이터베이스 스키마 정보를 효과적으로 활용하여 더 정확한 SQL 쿼리를 생성할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ee7e7e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 실습 환경 권장사항\n",
    "이 노트북을 실행하기 위한 권장 환경입니다.\n",
    "\n",
    "**Amazon SageMaker를 사용하는 경우:**\n",
    "- SageMaker 이미지: `sagemaker-distribution-cpu`\n",
    "- 커널: `Python 3`\n",
    "- 인스턴스 타입: `ml.m5.large`\n",
    "\n",
    "**참고:** 이 설정은 비용 효율적이면서도 충분한 성능을 제공합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612f32bc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 목차\n",
    "\n",
    "1. [필수 라이브러리 설치](#1단계-필수-라이브러리-설치)\n",
    "1. [AWS 서비스 연결 설정](#2단계-aws-서비스-연결-설정)\n",
    "1. [RAG 시스템 구성요소 준비](#3단계-rag-시스템-구성요소-준비)\n",
    "1. [벡터 임베딩 모델 설정](#4단계-벡터-임베딩-모델-설정)\n",
    "1. [데이터베이스 스키마 분석](#5단계-데이터베이스-스키마-분석)\n",
    "1. [질문 생성 및 벡터화](#6단계-질문-생성-및-벡터화)\n",
    "1. [RAG 기반 SQL 생성](#7단계-rag-기반-sql-생성)\n",
    "1. [실제 쿼리 실행 및 검증](#8단계-실제-쿼리-실행-및-검증)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171260d1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 학습 목표\n",
    "\n",
    "이 노트북을 완료하면 다음을 할 수 있게 됩니다:\n",
    "\n",
    "1. **RAG 시스템의 핵심 구성요소 이해**\n",
    "   - 벡터 임베딩과 유사도 검색의 원리\n",
    "   - 메타데이터와 자연어 질문의 매칭 방법\n",
    "   - FAISS 벡터 데이터베이스 활용법\n",
    "\n",
    "2. **실용적인 Text-to-SQL 시스템 구축**\n",
    "   - 데이터베이스 스키마 정보 자동 추출\n",
    "   - AI를 활용한 질문 생성 및 임베딩\n",
    "   - 의미적 유사성 기반 테이블 매칭\n",
    "\n",
    "3. **Amazon Bedrock과 AWS 서비스 통합**\n",
    "   - Bedrock 임베딩 모델 활용\n",
    "   - Athena 데이터베이스 연동\n",
    "   - 클라우드 기반 AI 시스템 구축\n",
    "\n",
    "## 왜 이것이 중요한가요?\n",
    "- **정확성 향상**: 관련 스키마 정보를 자동으로 찾아 더 정확한 SQL 생성\n",
    "- **확장성**: 수백 개의 테이블을 가진 대규모 데이터베이스에서도 효율적으로 작동\n",
    "- **사용자 경험**: 비개발자도 자연어로 복잡한 데이터 분석 수행 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7357e555",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## RAG 기반 Text-to-SQL 시스템 아키텍처\n",
    "\n",
    "### 기존 접근법의 한계\n",
    "기존의 Text-to-SQL 방법들은 다음과 같은 문제점이 있었습니다:\n",
    "- **스키마 정보 부족**: 모든 테이블 스키마를 프롬프트에 포함시키기 어려움\n",
    "- **토큰 제한**: LLM의 컨텍스트 길이 제한으로 인한 정보 손실\n",
    "- **비효율성**: 불필요한 테이블 정보까지 모두 전송\n",
    "\n",
    "### RAG 기반 해결책\n",
    "RAG를 활용하면 이러한 문제들을 효과적으로 해결할 수 있습니다:\n",
    "- **지능형 검색**: 질문과 관련된 테이블만 선별적으로 검색\n",
    "- **효율적인 활용**: 필요한 스키마 정보만 프롬프트에 포함\n",
    "- **확장성**: 대규모 데이터베이스에서도 빠른 응답 시간 보장"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "770bec8e-dd15-4b7d-8ec3-bc35baab0305",
   "metadata": {},
   "source": [
    "### RAG 시스템 구축 과정 상세 설명\n",
    "\n",
    "이 실습에서 구축할 RAG 시스템은 다음 4단계로 구성됩니다:\n",
    "\n",
    "**1단계: 데이터베이스 메타데이터 수집**\n",
    "먼저 Athena(AWS의 서버리스 쿼리 서비스)에서 TPC-DS 데이터셋의 메타데이터를 가져옵니다.\n",
    "- **메타데이터란?** 데이터에 대한 데이터로, 여기서는 테이블 이름, 컬럼 이름, 데이터 타입 등의 정보\n",
    "- **TPC-DS 데이터셋**: 소매업체의 판매 데이터를 모방한 표준 벤치마크 데이터셋\n",
    "\n",
    "**2단계: AI 기반 질문 생성**\n",
    "각 테이블의 스키마 정보를 바탕으로 LLM에게 \"이 테이블로 답할 수 있는 자연어 질문들\"을 생성하도록 요청합니다.\n",
    "- 예: customer 테이블 → \"어떤 고객이 가장 많이 구매했나요?\", \"고객 연령대별 분포는 어떻게 되나요?\"\n",
    "\n",
    "**3단계: 벡터 임베딩 및 저장**\n",
    "생성된 질문들과 메타데이터를 벡터로 변환하여 FAISS 벡터 데이터베이스에 저장합니다.\n",
    "- **임베딩(Embedding)**: 텍스트를 수치 벡터로 변환하여 컴퓨터가 의미를 이해할 수 있게 하는 기술\n",
    "- **FAISS**: 페이스북에서 개발한 고성능 벡터 검색 라이브러리\n",
    "- **의미적 유사성**: 단어의 표면적 일치가 아닌 의미적 관련성을 기준으로 유사도 측정\n",
    "\n",
    "**4단계: 지능형 프롬프트 구성**\n",
    "사용자 질문이 들어오면 벡터 검색을 통해 관련 테이블을 찾고, 해당 스키마 정보만을 포함한 효율적인 프롬프트를 구성하여 SQL을 생성합니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c81e0a1c",
   "metadata": {},
   "source": [
    "![Alt text](./content/rag.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50273671",
   "metadata": {},
   "source": [
    "### 사용할 도구들 소개\n",
    "\n",
    "이 실습에서는 다음 라이브러리와 도구들을 사용합니다:\n",
    "\n",
    "**핵심 라이브러리:**\n",
    "- **LangChain**: AI 애플리케이션 개발을 위한 프레임워크\n",
    "- **Amazon Bedrock SDK (boto3)**: AWS AI 서비스 접근을 위한 라이브러리\n",
    "- **FAISS**: 고성능 벡터 유사도 검색 라이브러리\n",
    "- **SQLAlchemy**: 파이썬 데이터베이스 연결 및 쿼리 실행 도구\n",
    "\n",
    "**AWS 서비스:**\n",
    "- **Amazon Bedrock**: 완전 관리형 AI 서비스 (임베딩 모델 제공)\n",
    "- **Amazon Athena**: 서버리스 SQL 쿼리 서비스\n",
    "- **TPC-DS on S3**: 표준 벤치마크 데이터셋\n",
    "\n",
    "각 도구의 역할을 이해하면 전체 시스템이 어떻게 작동하는지 파악하기 쉬워집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b00409e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1단계: 필수 라이브러리 설치\n",
    "\n",
    "RAG 기반 Text-to-SQL 시스템 구축을 위해 필요한 모든 라이브러리를 설치합니다.\n",
    "\n",
    "**설치되는 라이브러리의 역할:**\n",
    "- `sqlalchemy`: 데이터베이스 연결 및 쿼리 실행\n",
    "- `boto3`: AWS 서비스 연결 (Bedrock, Athena)\n",
    "- `langchain` & `langchain-aws`: AI 애플리케이션 개발 프레임워크\n",
    "- `faiss-cpu`: 벡터 검색을 위한 고성능 라이브러리\n",
    "- `PyAthena`: Amazon Athena 전용 커넥터\n",
    "- `jinja2`: 프롬프트 템플릿 처리\n",
    "- `jq`: JSON 데이터 처리\n",
    "\n",
    "**설치 시 참고사항**: \n",
    "일부 의존성 충돌 경고가 나타날 수 있지만, 이번 실습에는 영향을 주지 않으므로 무시하셔도 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455ba14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m ensurepip --upgrade\n",
    "%pip install -qU sqlalchemy\n",
    "%pip install -q \"boto3~=1.34\" \n",
    "%pip install -qU jinja2\n",
    "%pip install -qU botocore\n",
    "%pip install -qU pandas\n",
    "%pip install -qU PyAthena\n",
    "%pip install -qU faiss-cpu\n",
    "%pip install -qU langchain\n",
    "%pip install -qU langchain-aws\n",
    "%pip install -qU jq"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c1fda97-9150-484a-8cfa-86ec9568fc61",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2단계: 필요한 라이브러리 가져오기\n",
    "\n",
    "RAG 기반 Text-to-SQL 시스템 구축을 위한 모든 라이브러리를 가져옵니다.\n",
    "\n",
    "**주요 라이브러리 소개:**\n",
    "- `boto3`: AWS 서비스 (Bedrock, Athena) 접근\n",
    "- `langchain`: AI 애플리케이션 개발 프레임워크\n",
    "- `BedrockEmbeddings`: Amazon Bedrock 임베딩 모델 인터페이스\n",
    "- `FAISS`: 고성능 벡터 검색 엔진\n",
    "- `SQLAlchemy`: 데이터베이스 연결 및 메타데이터 조회\n",
    "- `din_sql_lib`: DIN-SQL 방법론 구현체 (SQL 생성용)\n",
    "- `utilities`: 워크샵용 유틸리티 함수들\n",
    "\n",
    "이 라이브러리들이 함께 작동하여 완전한 RAG 시스템을 구성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c70660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from functools import partial\n",
    "import json\n",
    "import re\n",
    "\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "from langchain.document_loaders.json_loader import JSONLoader\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_aws import BedrockEmbeddings\n",
    "from functools import reduce\n",
    "from langchain.prompts import PromptTemplate\n",
    "from sqlalchemy import MetaData\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "sys.path.append('../')\n",
    "from libs.din_sql import din_sql_lib as dsl\n",
    "import utilities as u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07958746-7313-484a-887b-167b8d8acf31",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3단계: AWS 서비스 연결 설정\n",
    "\n",
    "Amazon Athena와 Bedrock에 연결하기 위한 구성 정보를 설정합니다.\n",
    "\n",
    "**설정되는 구성 정보:**\n",
    "- **ATHENA_RESULTS_S3_LOCATION**: 쿼리 결과가 저장될 S3 버킷 위치\n",
    "- **ATHENA_CATALOG_NAME**: 사용할 Athena 데이터 카탈로그 이름\n",
    "- **DB_NAME**: 연결할 데이터베이스 이름 (tpcds1)\n",
    "- **DB_FAISS_PATH**: FAISS 벡터 데이터베이스가 저장될 로컬 경로\n",
    "\n",
    "이 정보들은 CloudFormation 스택에서 자동으로 생성되어 추출됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2212b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATHENA_RESULTS_S3_LOCATION, ATHENA_CATALOG_NAME = \\\n",
    "    u.extract_CF_outputs(\"AthenaResultsS3Location\", \"AthenaCatalogName\")\n",
    "DB_NAME = \"tpcds1\"\n",
    "DB_FAISS_PATH = './vectorstore/db_faiss'\n",
    "\n",
    "ATHENA_RESULTS_S3_LOCATION, ATHENA_CATALOG_NAME, DB_NAME, DB_FAISS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9676f804-f74f-44b5-918a-36cbcc74ebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id: str = \"anthropic.claude-v2\"\n",
    "# model_id: str = \"amazon.titan-tg1-large\"\n",
    "temperature: float = 0.2\n",
    "top_k: int = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcd2cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_region = athena_region = boto3.session.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18230081",
   "metadata": {},
   "outputs": [],
   "source": [
    "retry_config = Config(retries={'max_attempts': 100})\n",
    "session = boto3.Session(region_name=bedrock_region)\n",
    "bedrock = session.client('bedrock-runtime', region_name=bedrock_region,\n",
    "                         config=retry_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce22c308-ebbf-4ef5-a823-832b7c236e31",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4단계: 핵심 도우미 함수 구성\n",
    "\n",
    "RAG 시스템의 핵심 기능을 담당하는 도우미 함수들을 준비합니다.\n",
    "\n",
    "#### Bedrock 호출 함수 설정\n",
    "먼저 Amazon Bedrock과의 상호작용을 간소화하는 함수를 설정합니다. `partial` 함수를 사용하여 매번 반복되는 파라미터들을 미리 고정해둡니다.\n",
    "\n",
    "**설정되는 파라미터들:**\n",
    "- **model_id**: 사용할 AI 모델 (Claude V2)\n",
    "- **temperature**: 생성 결과의 창의성 조절 (0.2 = 보수적)\n",
    "- **top_k**: 토큰 선택 시 고려할 후보 수 (200개)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695b8503-cc1a-477b-a5dc-960a3a67ef3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_bedrock = partial(u.run_bedrock_simple_prompt,\n",
    "                      system_prompts=[],\n",
    "                      model_id=model_id,\n",
    "                      temperature=temperature,\n",
    "                      top_k=top_k)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24f7187d",
   "metadata": {},
   "source": [
    "#### 질문 생성 결과 저장 함수\n",
    "\n",
    "LLM이 각 테이블에 대해 생성한 자연어 질문들을 JSON 파일로 저장하는 함수입니다.\n",
    "\n",
    "**이 함수의 역할:**\n",
    "1. **텍스트 파싱**: LLM의 응답에서 개별 질문들을 추출\n",
    "2. **데이터 구조화**: 각 질문을 테이블명, 스키마 정보와 함께 구조화\n",
    "3. **JSON 저장**: 나중에 벡터화할 수 있도록 JSON 형태로 저장\n",
    "\n",
    "**저장되는 데이터 구조:**\n",
    "```json\n",
    "{\n",
    "  \"tableName\": \"customer\",\n",
    "  \"question\": \"어떤 고객이 가장 많이 구매했나요?\",\n",
    "  \"tableSchema\": \"c_customer_sk|c_first_name|c_last_name|...\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e571d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_questions_to_file(question_list_filename: str,\n",
    "                            table_name: str,\n",
    "                            table_schema, answer):\n",
    "    data_list = []\n",
    "    question_list_obj = answer\n",
    "    questions_list = question_list_obj.splitlines()\n",
    "    print(questions_list)\n",
    "    # Open the file in write mode\n",
    "    with open(question_list_filename, mode=\"w\", newline=\"\") as file:\n",
    "        for question in questions_list:\n",
    "\n",
    "            # Skip if it doesn't really have a question\n",
    "            if \"?\" not in question:\n",
    "                continue\n",
    "\n",
    "            questionSplit = re.split(r\"\\d{1,5}.||. ||- \", question, maxsplit=1)\n",
    "            print(questionSplit)\n",
    "            question = questionSplit[1]\n",
    "            data = {\n",
    "                \"tableName\": table_name,\n",
    "                \"question\": question,\n",
    "                \"tableSchema\": table_schema.lstrip(\" \"),\n",
    "            }\n",
    "            data_list.append(data)\n",
    "\n",
    "        json.dump(data_list, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a0c538",
   "metadata": {},
   "source": [
    "#### 문서 처리 및 벡터화 준비 함수\n",
    "\n",
    "JSON으로 저장된 질문 데이터를 FAISS 벡터 데이터베이스에 인덱싱하기 위해 LangChain Document 형태로 변환하는 함수들입니다.\n",
    "\n",
    "**핵심 개념 설명:**\n",
    "- **LangChain Document**: 텍스트 내용(`page_content`)과 메타데이터(`metadata`)를 함께 저장하는 데이터 구조\n",
    "- **메타데이터**: 검색 시 필터링이나 정보 제공을 위한 추가 정보\n",
    "- **벡터화**: 텍스트를 숫자 벡터로 변환하여 의미적 유사성 계산을 가능하게 하는 과정\n",
    "\n",
    "이 함수들은 데이터를 벡터 검색에 최적화된 형태로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad760cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_docs_with_correct_metadata(documents):\n",
    "    \"\"\"\n",
    "    인덱싱에 필요한 올바른 메타데이터를 가진 새로운 문서 생성\n",
    "    \"\"\"\n",
    "    # 새로운 문서 목록을 반환할 예정\n",
    "    new_docs = []\n",
    "\n",
    "    # 각 문서에 대해\n",
    "    for doc in documents:\n",
    "        # 메타데이터와 내용 가져오기\n",
    "        metadata = doc.metadata\n",
    "        contents = json.loads(doc.page_content)\n",
    "\n",
    "        # 추가하고자 하는 새로운 메타데이터 계산\n",
    "        new_metadata = {\n",
    "            \"tableName\": contents[\"tableName\"],\n",
    "            \"question\": contents[\"question\"],\n",
    "            \"tableSchema\": contents[\"tableSchema\"],\n",
    "        }\n",
    "\n",
    "        # 문서의 새로운 메타데이터 출력\n",
    "        # print(new_metadata)\n",
    "\n",
    "        new_docs.append(\n",
    "            Document(page_content=new_metadata[\"question\"], metadata=new_metadata)\n",
    "        )\n",
    "\n",
    "    return new_docs\n",
    "\n",
    "def load_json_file(filename):\n",
    "    loader = JSONLoader(file_path=filename, jq_schema=\".[]\", text_content=False)\n",
    "\n",
    "    # 이것은 내부 Langchain 문서 데이터 구조입니다\n",
    "    docs = loader.load()\n",
    "    return docs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3a1d76a9",
   "metadata": {},
   "source": [
    "#### 통합 테이블 처리 함수\n",
    "\n",
    "이 함수는 RAG 시스템의 핵심으로, 각 테이블에 대해 다음 작업을 순차적으로 수행합니다:\n",
    "\n",
    "1. **AI 질문 생성**: 테이블 스키마를 분석하여 해당 테이블로 답할 수 있는 자연어 질문들을 생성\n",
    "2. **결과 저장**: 생성된 질문들을 JSON 파일로 저장\n",
    "3. **벡터 변환**: 질문들을 벡터로 변환하여 FAISS 데이터베이스에 저장\n",
    "4. **증분 업데이트**: 기존 벡터 DB가 있으면 새로운 테이블 정보를 추가로 병합\n",
    "\n",
    "**사용되는 프롬프트 전략:**\n",
    "- 테이블별 맞춤형 질문 생성\n",
    "- 비즈니스 용어 사용 강조\n",
    "- 다양한 질문 유형 (집계, 필터링, 정렬 등) 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4367048b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_table(schema, table_name,model_id,is_incremental, bedrock_embeddings):\n",
    "    \"\"\"\n",
    "    LLM에게 테이블 스키마를 검사하고, 해당 스키마로 답할 수 있는 질문들을 생성하도록 요청한 다음,\n",
    "    이러한 질문들을 파일에 저장하고, 모든 질문을 단일 벡터 DB에 로드합니다.\n",
    "\n",
    "    :schema         : 테이블 스키마\n",
    "    :table_name     : 테이블 이름\n",
    "    :model_id       : 모델 ID\n",
    "    :is_incremental : 증분 처리 여부\n",
    "    \"\"\"\n",
    "    print(f\"테이블 {table_name}을 스키마 {schema}와 함께 추가 중\")\n",
    "    prompt = f\"\"\"\n",
    "    {table_name} 테이블의 다음 스키마로 답할 수 있는 고유하고 상세한 질문들의 번호가 매겨진 목록만 반환하세요:\n",
    "    {schema}.\n",
    "    지시사항:\n",
    "        자연어 설명만 사용하세요.\n",
    "        SQL을 사용하지 마세요.\n",
    "        다양한 질문 목록을 생성하되, 질문들은 고유하고 상세해야 합니다.\n",
    "        질문들은 이해하고 답하기 쉬운 형식이어야 합니다.\n",
    "        테이블의 정보에 대해 가능한 많이 질문하세요.\n",
    "        한 번에 데이터의 여러 측면에 대해 질문할 수 있습니다.\n",
    "        질문은 '무엇을', '어떤', '어떻게', '언제' 또는 '할 수 있는가'로 시작해야 합니다. 변수 이름을 사용하세요.\n",
    "        질문들은 관련된 비즈니스 어휘와 용어만 사용해야 합니다.\n",
    "        출력에 컬럼명을 사용하지 마세요 - 관련된 자연어 설명만 사용하세요.\n",
    "        숫자 값을 출력하지 마세요.\n",
    "        번호가 매겨진 목록으로 시작하는 질문들을 출력하세요.\n",
    "\n",
    "        \\n 질문들: 1.\n",
    "        \"\"\"\n",
    "    answer = run_bedrock(prompt=prompt)\n",
    "    question_list_filename = f\"../questionList{table_name}.json\"\n",
    "    print(f\"질문을 {question_list_filename}에 저장 중, 스키마 {schema}, \"\n",
    "          f\"테이블 이름 {table_name}, 답변 {answer}.\\n\\n\")\n",
    "    write_questions_to_file(question_list_filename, table_name, schema, answer)\n",
    "    docs = load_json_file(question_list_filename)\n",
    "    docs = create_docs_with_correct_metadata(docs)\n",
    "    print(f\"문서들:\\n{docs}\")\n",
    "    new_questions = FAISS.from_documents(docs, bedrock_embeddings)\n",
    "    db_exists = True if os.path.exists(f\"{DB_FAISS_PATH}/index.faiss\") else False\n",
    "    # 새 테이블 추가\n",
    "    if is_incremental and db_exists:\n",
    "            question_db = FAISS.load_local(DB_FAISS_PATH, bedrock_embeddings,\n",
    "                                           allow_dangerous_deserialization=True)\n",
    "            question_db.merge_from(new_questions)\n",
    "            question_db.save_local(DB_FAISS_PATH)\n",
    "    # 처음 로드\n",
    "    else:\n",
    "        print(f\"is_incremental이 {str(is_incremental)}로 설정되었고/또는 벡터 DB를 찾을 수 없습니다. 생성 중...\")\n",
    "        new_questions.save_local(DB_FAISS_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a486f1a5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 5단계: Amazon Bedrock 임베딩 모델 설정\n",
    "\n",
    "텍스트를 벡터로 변환하는 임베딩 모델을 설정합니다.\n",
    "\n",
    "**임베딩 모델이란?**\n",
    "텍스트를 고차원 숫자 벡터로 변환하는 AI 모델입니다. 이를 통해 컴퓨터가 텍스트의 의미를 이해하고 유사성을 계산할 수 있게 됩니다.\n",
    "\n",
    "**Amazon Bedrock 임베딩의 장점:**\n",
    "- **완전 관리형**: 모델 호스팅, 스케일링을 AWS가 자동 처리\n",
    "- **고성능**: 실시간 임베딩 생성 가능\n",
    "- **다국어 지원**: 한국어를 포함한 다양한 언어 지원\n",
    "- **보안**: AWS의 보안 정책과 통합\n",
    "\n",
    "이 설정으로 LangChain의 BedrockEmbeddings 클래스가 초기화됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb53761",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_embeddings = BedrockEmbeddings(client=bedrock)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "49fc5e86",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 6단계: TPC-DS 데이터셋 스키마 정보 수집\n",
    "\n",
    "Amazon Athena에서 TPC-DS 데이터셋의 모든 테이블 구조 정보를 자동으로 수집합니다.\n",
    "\n",
    "**TPC-DS 데이터셋 소개:**\n",
    "- **TPC-DS**: Transaction Processing Performance Council - Decision Support의 줄임말\n",
    "- **표준 벤치마크**: 데이터 웨어하우스 성능 측정을 위한 국제 표준 데이터셋\n",
    "- **실제 비즈니스 시나리오**: 소매업체의 판매, 고객, 재고 등 실제 업무를 모방\n",
    "- **복잡한 관계**: 약 25개 테이블이 서로 복잡하게 연결된 구조\n",
    "\n",
    "**메타데이터 수집 과정:**\n",
    "1. SQLAlchemy를 통해 Athena 연결\n",
    "2. 데이터베이스 메타데이터 자동 반영 (reflection)\n",
    "3. 각 테이블의 컬럼 정보 추출\n",
    "4. 파이프(|)로 구분된 문자열 형태로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f4afd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sqlalchemy_athena(database, catalog, s3stagingathena, region):\n",
    "    athena_connection_str = f'awsathena+rest://:@athena.{region}.amazonaws.com:443/{database}?s3_staging_dir={s3stagingathena}&catalog_name={catalog}'\n",
    "    # Athena 엔진 생성\n",
    "    return create_engine(athena_connection_str)\n",
    "\n",
    "\n",
    "def get_tpc_ds_dataset(database, catalog, s3stagingathena, region):\n",
    "    \"\"\" 데이터베이스 스키마 반영 \"\"\"\n",
    "\n",
    "    column_table  = []\n",
    "    columns_str = ''\n",
    "    table_name = ''\n",
    "    metadata = MetaData()\n",
    "    engine = get_sqlalchemy_athena(database, catalog, s3stagingathena, region)\n",
    "    metadata.reflect(bind=engine)\n",
    "\n",
    "    # 테이블 이름 목록 가져오기\n",
    "    print(metadata.tables.keys()) \n",
    "\n",
    "    # 테이블별로 반복\n",
    "    for table in metadata.tables:\n",
    "        print(f\"테이블: {table}\")\n",
    "        table_name = table\n",
    "        columns_str = \"\"\n",
    "        print(f\"스키마: {metadata.tables[table].schema}\")\n",
    "        print(f\"컬럼들: {metadata.tables[table].columns.keys()}\")\n",
    "        for column in metadata.tables[table].columns.keys():\n",
    "            columns_str = columns_str + f\"{column}\" + \"|\"\n",
    "        column_table.append((columns_str, table_name))\n",
    "    return column_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46f4c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpc_ds = get_tpc_ds_dataset(DB_NAME, ATHENA_CATALOG_NAME,\n",
    "                            ATHENA_RESULTS_S3_LOCATION, athena_region)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fbb3a532",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 7단계: AI 기반 질문 생성 및 벡터 임베딩\n",
    "\n",
    "이제 핵심 단계입니다! 각 테이블에 대해 AI가 자연어 질문을 생성하고, 이를 벡터로 변환하여 검색 가능한 형태로 저장합니다.\n",
    "\n",
    "**이 과정에서 일어나는 일:**\n",
    "\n",
    "1. **테이블별 질문 생성**\n",
    "   - 각 테이블의 스키마를 Claude에게 전달\n",
    "   - \"이 테이블로 답할 수 있는 자연어 질문들을 생성해줘\"라고 요청\n",
    "   - 비즈니스 용어를 사용한 다양한 질문들이 생성됨\n",
    "\n",
    "2. **질문 저장 및 구조화**\n",
    "   - 생성된 질문들을 JSON 파일로 저장\n",
    "   - 테이블명, 스키마 정보, 질문을 함께 저장\n",
    "\n",
    "3. **벡터 변환 및 인덱싱**\n",
    "   - 각 질문을 Bedrock 임베딩 모델로 벡터화\n",
    "   - FAISS 벡터 데이터베이스에 저장하여 빠른 검색 가능\n",
    "\n",
    "**예상 소요 시간**: 약 5분 (테이블 수와 생성되는 질문 수에 따라 변동)\n",
    "\n",
    "**생성되는 질문 예시:**\n",
    "- customer 테이블: \"어떤 고객이 가장 많이 구매했나요?\", \"고객 연령대별 분포는?\"\n",
    "- web_sales 테이블: \"월별 웹 판매 추이는?\", \"가장 인기 있는 상품은?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2cdf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in tpc_ds:\n",
    "    print(x)\n",
    "    schema, table_name = x\n",
    "    add_new_table(\n",
    "        schema=schema,\n",
    "        table_name=table_name,\n",
    "        model_id=model_id,\n",
    "        is_incremental=True,\n",
    "        bedrock_embeddings=bedrock_embeddings)\n",
    "print(\"\\n-----------------\\nFinished embedding metadata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0ff71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_db = FAISS.load_local(DB_FAISS_PATH, bedrock_embeddings,\n",
    "                               allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d87ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Find the top 10 customer name by total dollars spent\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada34d48",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 8단계: 지능형 테이블 검색 및 SQL 생성\n",
    "\n",
    "이제 구축된 RAG 시스템을 활용하여 실제로 자연어 질문을 SQL로 변환해보겠습니다!\n",
    "\n",
    "**RAG 검색 과정:**\n",
    "1. **사용자 질문 분석**: \"Find the top 10 customer name by total dollars spent\"\n",
    "2. **의미적 검색**: 질문을 벡터로 변환하여 유사한 질문들을 FAISS에서 검색\n",
    "3. **관련 테이블 식별**: 검색 결과에서 관련 테이블들과 스키마 정보 추출\n",
    "4. **키워드 매칭**: 추가로 질문의 키워드와 테이블명이 일치하는 테이블도 포함\n",
    "\n",
    "**하이브리드 검색 전략:**\n",
    "- **의미적 검색**: 벡터 유사도 기반 (customer, sales 관련 질문 매칭)\n",
    "- **키워드 검색**: 단어 일치 기반 (질문에 \"customer\"가 있으면 customer 테이블 포함)\n",
    "\n",
    "이 두 방법을 결합하여 누락 없이 관련 테이블을 찾아냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454d0043",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {}\n",
    "results_with_scores = question_db.similarity_search_with_score(query)\n",
    "for doc, score in results_with_scores:\n",
    "    print(doc.metadata['question'])\n",
    "    schema[doc.metadata['tableName']] = doc.metadata['tableSchema']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b011b7",
   "metadata": {},
   "source": [
    "Anthropic Claude v2 모델로 DIN_SQL 클래스를 초기화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70967c16-979e-4326-8ac5-0a28be932609",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf5cc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "din_sql = dsl.DIN_SQL(bedrock_model_id=model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21675ed4",
   "metadata": {},
   "source": [
    "쿼리 실행을 준비하기 위해 Athena에 연결합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a142a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "din_sql.athena_connect(catalog_name=ATHENA_CATALOG_NAME, \n",
    "               db_name=DB_NAME, \n",
    "               s3_prefix=ATHENA_RESULTS_S3_LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2692f8",
   "metadata": {},
   "source": [
    "이제 질문의 어떤 단어와도 일치하는 테이블 이름이 있는 테이블 메타데이터를 `schema` 객체에 추가하여, 놓칠 수 있는 명백한 일치 항목을 포착합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfac1432",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tables = din_sql.find_tables(DB_NAME)\n",
    "list_words = query.split(\" \")\n",
    "\n",
    "intersection = reduce(lambda acc, x: acc + [x] if x in list_words and x not in acc else acc,\n",
    "                      list_tables, [])\n",
    "for table in intersection:\n",
    "    if table in schema:\n",
    "        print(\"exists\")\n",
    "    else:\n",
    "        schema_name = din_sql.get_schema(DB_NAME, table)\n",
    "        schema[table] = schema_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ae5e61",
   "metadata": {},
   "source": [
    "이제 `schema` 객체에 무엇이 들어있는지 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0ab256",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb64e31",
   "metadata": {},
   "source": [
    "#### 최적화된 프롬프트 구성\n",
    "\n",
    "검색된 스키마 정보를 바탕으로 효율적인 프롬프트를 구성합니다.\n",
    "\n",
    "**프롬프트 설계의 핵심 원칙:**\n",
    "\n",
    "1. **명확한 지시사항**: 무엇을 해야 하는지 단계별로 명시\n",
    "2. **스키마 정보 통합**: 관련 테이블의 스키마만 선별적으로 포함\n",
    "3. **실전 예시 제공**: Few-shot learning을 위한 구체적인 예시\n",
    "4. **출력 형식 지정**: XML 태그를 사용한 구조화된 출력\n",
    "\n",
    "**기존 방식과의 차이점:**\n",
    "- **기존**: 모든 테이블 정보를 프롬프트에 포함 → 토큰 낭비, 혼동 가능성\n",
    "- **RAG 방식**: 관련 테이블만 선별적 포함 → 효율성, 정확성 향상\n",
    "\n",
    "이제 실제 프롬프트를 확인하고 Claude의 응답을 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c55bf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"<Instructions>\n",
    "            <database_schema></database_schema> 태그 안의 데이터베이스 스키마를 읽고 다음을 수행하세요:\n",
    "            이 스키마는 테이블 이름과 파이프로 구분된 스키마의 json 목록을 포함합니다:\n",
    "            1. 질문에 답하기 위해 문법적으로 올바른 awsathena 쿼리를 생성하세요.\n",
    "            2. 특정 테이블의 모든 컬럼을 쿼리하지 마세요. 질문과 관련된 몇 개의 컬럼만 요청하세요.\n",
    "            3. 스키마 설명에서 볼 수 있는 컬럼 이름만 사용하도록 주의하세요.\n",
    "            4. 존재하지 않는 컬럼을 쿼리하지 않도록 주의하세요.\n",
    "            5. 어떤 컬럼이 어떤 테이블에 속하는지 주의하세요.\n",
    "            6. 필요할 때 테이블 이름으로 컬럼 이름을 한정하세요. 다음 형식을 사용해야 하며, 각각 한 줄씩 작성하세요:\n",
    "            7. SQL 쿼리를 <sql></sql> 태그 안에 반환하세요.\n",
    "        </Instructions>\n",
    "\n",
    "        <database_schema>{schema}</database_schema>\n",
    "\n",
    "        <examples>\n",
    "        <question>\"사용자가 몇 명인가요?\"</question>\n",
    "        <sql>SELECT SUM(users) FROM customers</sql>\n",
    "\n",
    "        <question>\"모바일 사용자가 몇 명인가요?\"</question>\n",
    "        <sql>SELECT SUM(users) FROM customer WHERE source_medium='Mobile'</sql>\n",
    "        </examples>\n",
    "\n",
    "        <question>{input_question}</question>\n",
    "        \"\"\")\n",
    "prompt = prompt_template.format(schema=schema, input_question=query)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9ff749",
   "metadata": {},
   "source": [
    "#### Claude를 통한 SQL 생성\n",
    "\n",
    "구성된 프롬프트를 Claude에게 전송하여 SQL 쿼리를 생성합니다.\n",
    "\n",
    "**생성 과정:**\n",
    "1. **프롬프트 전송**: 질문 + 관련 스키마 정보 + 지시사항\n",
    "2. **AI 추론**: Claude가 테이블 관계를 분석하고 적절한 SQL 구성\n",
    "3. **결과 추출**: XML 태그로 구분된 SQL 쿼리 추출\n",
    "\n",
    "**예상되는 SQL 특징:**\n",
    "- 적절한 JOIN 조건으로 customer와 web_sales 테이블 연결\n",
    "- 고객별 총 구매액 계산을 위한 SUM 집계 함수 사용\n",
    "- TOP 10 추출을 위한 ORDER BY와 LIMIT 절"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81addd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = run_bedrock(prompt=prompt)\n",
    "print(answer)\n",
    "sql = u.extract_tag(answer, \"sql\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d643e74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71c636d",
   "metadata": {},
   "source": [
    "#### 실제 데이터 검증\n",
    "\n",
    "생성된 SQL 쿼리를 실제 데이터베이스에서 실행하여 결과를 확인해보겠습니다.\n",
    "\n",
    "**검증 포인트:**\n",
    "1. **쿼리 실행 성공**: 문법 오류 없이 실행되는가?\n",
    "2. **결과의 타당성**: 고객 이름과 구매액이 올바르게 나타나는가?\n",
    "3. **순서 정확성**: 구매액 기준으로 내림차순 정렬되어 있는가?\n",
    "4. **데이터 형태**: 예상한 형태의 결과가 반환되는가?\n",
    "\n",
    "성공적으로 실행되면 RAG 기반 Text-to-SQL 시스템이 완성된 것입니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fe7ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = din_sql.query(sql)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2664ee27-1aaf-4e94-ba77-dbddbae921bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
