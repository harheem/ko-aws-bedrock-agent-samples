{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0916a3a-e402-48b7-a775-ce739e4aeaf4",
   "metadata": {},
   "source": "# RAG(검색 증강 생성)를 사용한 자연어를 SQL로 변환하기\nRAG를 활용하여 자연어를 SQL로 변환하는 성능을 향상시키는 방법",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b5ee7e7e",
   "metadata": {},
   "source": "---\n## 권장 SageMaker 환경\n\nSageMaker 이미지: sagemaker-distribution-cpu\n\n커널: Python 3\n\n인스턴스 타입: ml.m5.large",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "612f32bc",
   "metadata": {},
   "source": "---\n## 목차\n\n1. [필요한 패키지 설치](#1단계-필요한-패키지-설치)\n1. [Bedrock 임베딩 모델 구성](#2단계-bedrock-임베딩-모델과-llm-구성)\n1. [Athena와 Bedrock 클라이언트 구성](#3단계-athena와-bedrock-클라이언트-구성)\n1. [도우미 함수 생성](#4단계-도우미-함수-생성)\n1. [Bedrock 임베딩 모델 구성](#5단계-bedrock-임베딩-모델-구성)\n1. [TPC-DS 메타데이터 가져오기](#6단계-tpc-ds-데이터셋-테이블과-컬럼-정보-가져오기)\n1. [질문과 메타데이터 임베딩](#7단계-모든-질문과-메타데이터-임베딩하기)\n1. [프롬프트 구성 및 쿼리 생성](#8단계-프롬프트-구성하여-sql-쿼리-생성하기)",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a6f2bd54",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171260d1",
   "metadata": {},
   "source": "## 목표\n이 노트북은 자연어 질문을 해당 질문에 답하는 SQL 쿼리로 변환하는 방법을 구현하는 데 도움이 되는 코드 예제를 제공합니다.",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7357e555",
   "metadata": {},
   "source": "---\n## 자연어-SQL 변환 문제에 대한 접근 방식",
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "770bec8e-dd15-4b7d-8ec3-bc35baab0305",
   "metadata": {},
   "source": "Bedrock 임베딩(embedding) 모델과 LLM(대형 언어 모델)을 설정하여 테이블 메타데이터를 임베딩하는 과정을 살펴보겠습니다.\n\n**RAG(검색 증강 생성)란?**\nRAG는 기존 지식 베이스에서 관련 정보를 검색하여 AI 모델의 답변을 향상시키는 기술입니다. 이를 통해 더 정확하고 맥락에 맞는 답변을 생성할 수 있습니다.\n\n**1단계: Athena에서 메타데이터 가져오기**\n먼저 Athena(AWS의 쿼리 서비스)에서 데이터베이스의 메타데이터(테이블 구조, 컬럼 정보 등)를 가져옵니다.\n\n**2단계: 질문 생성**\n메타데이터를 활용하여 LLM에게 각 테이블로 답할 수 있는 가능한 질문들을 생성하도록 요청합니다.\n\n**3단계: 벡터 저장소에 임베딩**\n모든 메타데이터와 생성된 질문들을 벡터 저장소에 임베딩합니다. \n- **임베딩(Embedding)**: 텍스트를 숫자 벡터로 변환하여 컴퓨터가 의미를 이해할 수 있게 하는 기술\n- **FAISS**: 페이스북에서 개발한 빠른 벡터 검색 라이브러리\n- **의미적 유사성(Semantic Similarity)**: 단어의 의미적 관련성을 측정하는 방법\n\n**4단계: 프롬프트 설계**\n마지막으로 임베딩, 지시사항, 몇 개의 예시(few-shot examples), 그리고 물론 우리의 질문을 포함하는 강력한 프롬프트를 설계합니다.",
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c81e0a1c",
   "metadata": {},
   "source": [
    "![Alt text](./content/rag.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50273671",
   "metadata": {},
   "source": "### 사용 도구\nLangchain, Amazon Bedrock SDK (boto3)",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "5b00409e",
   "metadata": {},
   "source": "---\n### 1단계: 필요한 패키지 설치\n\n이 노트북을 실행하는 데 필요한 모든 패키지를 설치합니다.",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455ba14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m ensurepip --upgrade\n",
    "%pip install -qU sqlalchemy\n",
    "%pip install -q \"boto3~=1.34\" \n",
    "%pip install -qU jinja2\n",
    "%pip install -qU botocore\n",
    "%pip install -qU pandas\n",
    "%pip install -qU PyAthena\n",
    "%pip install -qU faiss-cpu\n",
    "%pip install -qU langchain\n",
    "%pip install -qU langchain-aws\n",
    "%pip install -qU jq"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c1fda97-9150-484a-8cfa-86ec9568fc61",
   "metadata": {},
   "source": "---\n### 2단계: Bedrock 임베딩 모델과 LLM 구성",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c70660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from functools import partial\n",
    "import json\n",
    "import re\n",
    "\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "from langchain.document_loaders.json_loader import JSONLoader\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_aws import BedrockEmbeddings\n",
    "from functools import reduce\n",
    "from langchain.prompts import PromptTemplate\n",
    "from sqlalchemy import MetaData\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "sys.path.append('../')\n",
    "from libs.din_sql import din_sql_lib as dsl\n",
    "import utilities as u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07958746-7313-484a-887b-167b8d8acf31",
   "metadata": {},
   "source": "---\n### 3단계: Athena와 Bedrock 클라이언트 구성",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2212b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATHENA_RESULTS_S3_LOCATION, ATHENA_CATALOG_NAME = \\\n",
    "    u.extract_CF_outputs(\"AthenaResultsS3Location\", \"AthenaCatalogName\")\n",
    "DB_NAME = \"tpcds1\"\n",
    "DB_FAISS_PATH = './vectorstore/db_faiss'\n",
    "\n",
    "ATHENA_RESULTS_S3_LOCATION, ATHENA_CATALOG_NAME, DB_NAME, DB_FAISS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9676f804-f74f-44b5-918a-36cbcc74ebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id: str = \"anthropic.claude-v2\"\n",
    "# model_id: str = \"amazon.titan-tg1-large\"\n",
    "temperature: float = 0.2\n",
    "top_k: int = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcd2cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_region = athena_region = boto3.session.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18230081",
   "metadata": {},
   "outputs": [],
   "source": [
    "retry_config = Config(retries={'max_attempts': 100})\n",
    "session = boto3.Session(region_name=bedrock_region)\n",
    "bedrock = session.client('bedrock-runtime', region_name=bedrock_region,\n",
    "                         config=retry_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce22c308-ebbf-4ef5-a823-832b7c236e31",
   "metadata": {},
   "source": "---\n### 4단계: 도우미 함수 생성",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695b8503-cc1a-477b-a5dc-960a3a67ef3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_bedrock = partial(u.run_bedrock_simple_prompt,\n",
    "                      system_prompts=[],\n",
    "                      model_id=model_id,\n",
    "                      temperature=temperature,\n",
    "                      top_k=top_k)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24f7187d",
   "metadata": {},
   "source": "LLM이 주어진 테이블과 컬럼으로 답할 수 있는 질문 목록을 반환하면, `write_questions_to_file` 메서드가 이를 로컬에 json 파일로 저장하는 역할을 합니다.",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e571d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_questions_to_file(question_list_filename: str,\n",
    "                            table_name: str,\n",
    "                            table_schema, answer):\n",
    "    data_list = []\n",
    "    question_list_obj = answer\n",
    "    questions_list = question_list_obj.splitlines()\n",
    "    print(questions_list)\n",
    "    # Open the file in write mode\n",
    "    with open(question_list_filename, mode=\"w\", newline=\"\") as file:\n",
    "        for question in questions_list:\n",
    "\n",
    "            # Skip if it doesn't really have a question\n",
    "            if \"?\" not in question:\n",
    "                continue\n",
    "\n",
    "            questionSplit = re.split(r\"\\d{1,5}.||. ||- \", question, maxsplit=1)\n",
    "            print(questionSplit)\n",
    "            question = questionSplit[1]\n",
    "            data = {\n",
    "                \"tableName\": table_name,\n",
    "                \"question\": question,\n",
    "                \"tableSchema\": table_schema.lstrip(\" \"),\n",
    "            }\n",
    "            data_list.append(data)\n",
    "\n",
    "        json.dump(data_list, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a0c538",
   "metadata": {},
   "source": "문서 목록을 받아서 메타데이터가 첨부된 동일한 문서 목록을 반환하는 메서드가 필요합니다. 또한 JSON을 로드하여 JSON 객체를 반환하는 도우미 함수도 필요합니다.",
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "8ad760cf",
   "metadata": {},
   "outputs": [],
   "source": "def create_docs_with_correct_metadata(documents):\n    \"\"\"\n    인덱싱에 필요한 올바른 메타데이터를 가진 새로운 문서 생성\n    \"\"\"\n    # 새로운 문서 목록을 반환할 예정\n    new_docs = []\n\n    # 각 문서에 대해\n    for doc in documents:\n        # 메타데이터와 내용 가져오기\n        metadata = doc.metadata\n        contents = json.loads(doc.page_content)\n\n        # 추가하고자 하는 새로운 메타데이터 계산\n        new_metadata = {\n            \"tableName\": contents[\"tableName\"],\n            \"question\": contents[\"question\"],\n            \"tableSchema\": contents[\"tableSchema\"],\n        }\n\n        # 문서의 새로운 메타데이터 출력\n        # print(new_metadata)\n\n        new_docs.append(\n            Document(page_content=new_metadata[\"question\"], metadata=new_metadata)\n        )\n\n    return new_docs\n\ndef load_json_file(filename):\n    loader = JSONLoader(file_path=filename, jq_schema=\".[]\", text_content=False)\n\n    # 이것은 내부 Langchain 문서 데이터 구조입니다\n    docs = loader.load()\n    return docs"
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3a1d76a9",
   "metadata": {},
   "source": "이 함수는 LLM에게 테이블 스키마를 검사하고, 해당 스키마로 답할 수 있는 질문들을 생성하도록 요청한 다음, 이러한 질문들을 파일에 저장합니다. 마지막으로 모든 질문을 단일 벡터 데이터베이스에 추가합니다.\n아래 프롬프트는 자연어로 질문을 생성하는 데 사용되며, 질문과 테이블 메타데이터를 임베딩하는 모든 도우미 함수를 호출합니다.",
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "4367048b",
   "metadata": {},
   "outputs": [],
   "source": "def add_new_table(schema, table_name,model_id,is_incremental, bedrock_embeddings):\n    \"\"\"\n    LLM에게 테이블 스키마를 검사하고, 해당 스키마로 답할 수 있는 질문들을 생성하도록 요청한 다음,\n    이러한 질문들을 파일에 저장하고, 모든 질문을 단일 벡터 DB에 로드합니다.\n\n    :schema         : 테이블 스키마\n    :table_name     : 테이블 이름\n    :model_id       : 모델 ID\n    :is_incremental : 증분 처리 여부\n    \"\"\"\n    print(f\"테이블 {table_name}을 스키마 {schema}와 함께 추가 중\")\n    prompt = f\"\"\"\n    {table_name} 테이블의 다음 스키마로 답할 수 있는 고유하고 상세한 질문들의 번호가 매겨진 목록만 반환하세요:\n    {schema}.\n    지시사항:\n        자연어 설명만 사용하세요.\n        SQL을 사용하지 마세요.\n        다양한 질문 목록을 생성하되, 질문들은 고유하고 상세해야 합니다.\n        질문들은 이해하고 답하기 쉬운 형식이어야 합니다.\n        테이블의 정보에 대해 가능한 많이 질문하세요.\n        한 번에 데이터의 여러 측면에 대해 질문할 수 있습니다.\n        질문은 '무엇을', '어떤', '어떻게', '언제' 또는 '할 수 있는가'로 시작해야 합니다. 변수 이름을 사용하세요.\n        질문들은 관련된 비즈니스 어휘와 용어만 사용해야 합니다.\n        출력에 컬럼명을 사용하지 마세요 - 관련된 자연어 설명만 사용하세요.\n        숫자 값을 출력하지 마세요.\n        번호가 매겨진 목록으로 시작하는 질문들을 출력하세요.\n\n        \\n 질문들: 1.\n        \"\"\"\n    answer = run_bedrock(prompt=prompt)\n    question_list_filename = f\"../questionList{table_name}.json\"\n    print(f\"질문을 {question_list_filename}에 저장 중, 스키마 {schema}, \"\n          f\"테이블 이름 {table_name}, 답변 {answer}.\\n\\n\")\n    write_questions_to_file(question_list_filename, table_name, schema, answer)\n    docs = load_json_file(question_list_filename)\n    docs = create_docs_with_correct_metadata(docs)\n    print(f\"문서들:\\n{docs}\")\n    new_questions = FAISS.from_documents(docs, bedrock_embeddings)\n    db_exists = True if os.path.exists(f\"{DB_FAISS_PATH}/index.faiss\") else False\n    # 새 테이블 추가\n    if is_incremental and db_exists:\n            question_db = FAISS.load_local(DB_FAISS_PATH, bedrock_embeddings,\n                                           allow_dangerous_deserialization=True)\n            question_db.merge_from(new_questions)\n            question_db.save_local(DB_FAISS_PATH)\n    # 처음 로드\n    else:\n        print(f\"is_incremental이 {str(is_incremental)}로 설정되었고/또는 벡터 DB를 찾을 수 없습니다. 생성 중...\")\n        new_questions.save_local(DB_FAISS_PATH)"
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a486f1a5",
   "metadata": {},
   "source": " ---\n ### 5단계: Bedrock 임베딩 모델 구성\n 여기서는 텍스트를 벡터 임베딩으로 변환하는 LangChain 임베딩 모델을 생성합니다.\n \n **임베딩 모델이란?**\n 텍스트를 컴퓨터가 이해할 수 있는 숫자 벡터로 변환하는 AI 모델입니다. 이를 통해 텍스트 간의 의미적 유사성을 계산할 수 있습니다.",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb53761",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_embeddings = BedrockEmbeddings(client=bedrock)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "49fc5e86",
   "metadata": {},
   "source": " ---\n ### 6단계: TPC-DS 데이터셋 테이블과 컬럼 정보 가져오기\n \n **TPC-DS란?**\n TPC-DS는 데이터 웨어하우스 성능을 측정하기 위한 표준 벤치마크 데이터셋입니다. 실제 비즈니스 시나리오를 모방한 다양한 테이블과 데이터를 포함합니다.",
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "36f4afd5",
   "metadata": {},
   "outputs": [],
   "source": "def get_sqlalchemy_athena(database, catalog, s3stagingathena, region):\n    athena_connection_str = f'awsathena+rest://:@athena.{region}.amazonaws.com:443/{database}?s3_staging_dir={s3stagingathena}&catalog_name={catalog}'\n    # Athena 엔진 생성\n    return create_engine(athena_connection_str)\n\n\ndef get_tpc_ds_dataset(database, catalog, s3stagingathena, region):\n    \"\"\" 데이터베이스 스키마 반영 \"\"\"\n\n    column_table  = []\n    columns_str = ''\n    table_name = ''\n    metadata = MetaData()\n    engine = get_sqlalchemy_athena(database, catalog, s3stagingathena, region)\n    metadata.reflect(bind=engine)\n\n    # 테이블 이름 목록 가져오기\n    print(metadata.tables.keys()) \n\n    # 테이블별로 반복\n    for table in metadata.tables:\n        print(f\"테이블: {table}\")\n        table_name = table\n        columns_str = \"\"\n        print(f\"스키마: {metadata.tables[table].schema}\")\n        print(f\"컬럼들: {metadata.tables[table].columns.keys()}\")\n        for column in metadata.tables[table].columns.keys():\n            columns_str = columns_str + f\"{column}\" + \"|\"\n        column_table.append((columns_str, table_name))\n    return column_table"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46f4c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpc_ds = get_tpc_ds_dataset(DB_NAME, ATHENA_CATALOG_NAME,\n",
    "                            ATHENA_RESULTS_S3_LOCATION, athena_region)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fbb3a532",
   "metadata": {},
   "source": "---\n### 7단계: 모든 질문과 메타데이터 임베딩하기\n여기서는 도우미 함수를 사용하여 테이블 메타데이터를 임베딩하고 테이블에 대해 질문할 수 있는 가능한 질문들을 생성합니다.\n\n**이 과정에서 일어나는 일:**\n1. 각 테이블의 스키마를 분석\n2. AI가 해당 테이블로 답할 수 있는 자연어 질문들을 생성\n3. 질문들을 벡터로 변환하여 저장\n4. 나중에 사용자 질문과 유사한 질문을 빠르게 찾을 수 있도록 준비\n\n**다음 셀은 일반적으로 실행하는 데 약 5분 정도 걸립니다.**",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2cdf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in tpc_ds:\n",
    "    print(x)\n",
    "    schema, table_name = x\n",
    "    add_new_table(\n",
    "        schema=schema,\n",
    "        table_name=table_name,\n",
    "        model_id=model_id,\n",
    "        is_incremental=True,\n",
    "        bedrock_embeddings=bedrock_embeddings)\n",
    "print(\"\\n-----------------\\nFinished embedding metadata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0ff71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_db = FAISS.load_local(DB_FAISS_PATH, bedrock_embeddings,\n",
    "                               allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d87ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Find the top 10 customer name by total dollars spent\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada34d48",
   "metadata": {},
   "source": "---\n### 8단계: 프롬프트 구성하여 SQL 쿼리 생성하기\n먼저 유사성 검색과 키워드 검색을 모두 사용하여 질문의 의미적 의미를 바탕으로 가능한 일치 항목을 찾아 테이블과 컬럼 정보를 가져옵니다.\n\n**이 단계에서 하는 일:**\n1. 사용자의 자연어 질문을 분석\n2. 벡터 저장소에서 관련 테이블과 컬럼 정보 검색\n3. 검색된 정보를 바탕으로 SQL 쿼리 생성을 위한 프롬프트 구성",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454d0043",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {}\n",
    "results_with_scores = question_db.similarity_search_with_score(query)\n",
    "for doc, score in results_with_scores:\n",
    "    print(doc.metadata['question'])\n",
    "    schema[doc.metadata['tableName']] = doc.metadata['tableSchema']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b011b7",
   "metadata": {},
   "source": "Anthropic Claude v2 모델로 DIN_SQL 클래스를 초기화합니다.",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70967c16-979e-4326-8ac5-0a28be932609",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf5cc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "din_sql = dsl.DIN_SQL(bedrock_model_id=model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21675ed4",
   "metadata": {},
   "source": "쿼리 실행을 준비하기 위해 Athena에 연결합니다.",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a142a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "din_sql.athena_connect(catalog_name=ATHENA_CATALOG_NAME, \n",
    "               db_name=DB_NAME, \n",
    "               s3_prefix=ATHENA_RESULTS_S3_LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2692f8",
   "metadata": {},
   "source": "이제 질문의 어떤 단어와도 일치하는 테이블 이름이 있는 테이블 메타데이터를 `schema` 객체에 추가하여, 놓칠 수 있는 명백한 일치 항목을 포착합니다.",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfac1432",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tables = din_sql.find_tables(DB_NAME)\n",
    "list_words = query.split(\" \")\n",
    "\n",
    "intersection = reduce(lambda acc, x: acc + [x] if x in list_words and x not in acc else acc,\n",
    "                      list_tables, [])\n",
    "for table in intersection:\n",
    "    if table in schema:\n",
    "        print(\"exists\")\n",
    "    else:\n",
    "        schema_name = din_sql.get_schema(DB_NAME, table)\n",
    "        schema[table] = schema_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ae5e61",
   "metadata": {},
   "source": "이제 `schema` 객체에 무엇이 들어있는지 살펴보겠습니다.",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0ab256",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb64e31",
   "metadata": {},
   "source": "스키마 정보가 사용할 준비가 되었으므로, 이제 품질 있는 결과를 얻을 수 있는 프롬프트를 작성할 준비가 되었습니다. Claude 프롬프팅 모범 사례를 사용하는 다음 프롬프트를 살펴보고, 스키마가 지시사항에 어떻게 통합되는지 확인해보세요.",
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "6c55bf28",
   "metadata": {},
   "outputs": [],
   "source": "prompt_template = PromptTemplate.from_template(\n    \"\"\"<Instructions>\n            <database_schema></database_schema> 태그 안의 데이터베이스 스키마를 읽고 다음을 수행하세요:\n            이 스키마는 테이블 이름과 파이프로 구분된 스키마의 json 목록을 포함합니다:\n            1. 질문에 답하기 위해 문법적으로 올바른 awsathena 쿼리를 생성하세요.\n            2. 특정 테이블의 모든 컬럼을 쿼리하지 마세요. 질문과 관련된 몇 개의 컬럼만 요청하세요.\n            3. 스키마 설명에서 볼 수 있는 컬럼 이름만 사용하도록 주의하세요.\n            4. 존재하지 않는 컬럼을 쿼리하지 않도록 주의하세요.\n            5. 어떤 컬럼이 어떤 테이블에 속하는지 주의하세요.\n            6. 필요할 때 테이블 이름으로 컬럼 이름을 한정하세요. 다음 형식을 사용해야 하며, 각각 한 줄씩 작성하세요:\n            7. SQL 쿼리를 <sql></sql> 태그 안에 반환하세요.\n        </Instructions>\n\n        <database_schema>{schema}</database_schema>\n\n        <examples>\n        <question>\"사용자가 몇 명인가요?\"</question>\n        <sql>SELECT SUM(users) FROM customers</sql>\n\n        <question>\"모바일 사용자가 몇 명인가요?\"</question>\n        <sql>SELECT SUM(users) FROM customer WHERE source_medium='Mobile'</sql>\n        </examples>\n\n        <question>{input_question}</question>\n        \"\"\")\nprompt = prompt_template.format(schema=schema, input_question=query)\nprint(prompt)"
  },
  {
   "cell_type": "markdown",
   "id": "0d9ff749",
   "metadata": {},
   "source": "전체 프롬프트가 준비되었으므로, Claude에게 제출하여 어떤 결과를 얻을 수 있는지 확인해보겠습니다.",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81addd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = run_bedrock(prompt=prompt)\n",
    "print(answer)\n",
    "sql = u.extract_tag(answer, \"sql\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d643e74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71c636d",
   "metadata": {},
   "source": "생성한 이 쿼리로 데이터를 조회해보겠습니다.",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fe7ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = din_sql.query(sql)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2664ee27-1aaf-4e94-ba77-dbddbae921bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}